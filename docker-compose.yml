version: '3.8'

services:
  # Redis for Celery message broker
  redis:
    image: redis:7-alpine
    container_name: otis-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped
    networks:
      - otis-network

  # Jaeger for distributed tracing
  jaeger:
    image: jaegertracing/all-in-one:latest
    container_name: otis-jaeger
    ports:
      - "6831:6831/udp"  # Jaeger agent
      - "16686:16686"    # Jaeger UI
      - "14268:14268"    # Jaeger collector
    environment:
      - COLLECTOR_ZIPKIN_HOST_PORT=:9411
    restart: unless-stopped
    networks:
      - otis-network

  # API Service
  api:
    build:
      context: .
      dockerfile: docker/Dockerfile.api
    container_name: otis-api
    ports:
      - "${API_PORT:-8000}:8000"
    environment:
      - DATABASE_URL=postgresql://otis:otis_password@postgres:5432/otis
      - OLLAMA_BASE_URL=http://ollama:11434
      - CHROMA_PERSIST_DIRECTORY=/app/data/chroma
      - TELEGRAM_BOT_TOKEN=${TELEGRAM_BOT_TOKEN}
      - TELEGRAM_ADMIN_CHAT_ID=${TELEGRAM_ADMIN_CHAT_ID}
      - SECRET_KEY=${SECRET_KEY:-change-this-to-a-secure-random-key}
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
      - JAEGER_HOST=jaeger
      - JAEGER_PORT=6831
    volumes:
      - ./data/chroma:/app/data/chroma
      - ./data/logs:/app/data/logs
      - ./data/pending:/app/data/pending
    depends_on:
      - postgres
      - ollama
      - chroma
      - redis
      - jaeger
    restart: unless-stopped
    networks:
      - frontend-net  # Internet-facing
      - db-net        # Database access
      - ai-net        # AI services access
      - obs-net       # Observability
      # NO access to security-net
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/v1/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Docker Socket Proxy for secure socket access
  socket-proxy:
    image: tecnativa/docker-socket-proxy:latest
    container_name: otis-socket-proxy
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
    environment:
      - CONTAINERS=1 # Allow access to container-related endpoints
    restart: unless-stopped
    networks:
      - otis-network

  # Sandbox Runner Service
  runner:
    build:
      context: .
      dockerfile: docker/Dockerfile.runner
    container_name: otis-runner
    environment:
      - DATABASE_URL=postgresql://otis:otis_password@postgres:5432/otis
      # Point DOCKER_HOST to the secure proxy
      - DOCKER_HOST=tcp://socket-proxy:2375
    volumes:
      # - /var/run/docker.sock:/var/run/docker.sock # REMOVED for security
      - ./data/logs:/app/data/logs
    depends_on:
      - postgres
      - socket-proxy
    restart: unless-stopped
    networks:
      - otis-network

  # PostgreSQL Database
  postgres:
    image: postgres:15-alpine
    container_name: otis-postgres
    environment:
      - POSTGRES_USER=otis
      - POSTGRES_PASSWORD=otis_password
      - POSTGRES_DB=otis
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    restart: unless-stopped
    networks:
      - otis-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U otis"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Chroma Vector Store
  chroma:
    image: chromadb/chroma:latest
    container_name: otis-chroma
    ports:
      - "8001:8000"
    volumes:
      - chroma_data:/chroma/chroma
    environment:
      - IS_PERSISTENT=TRUE
      - ANONYMIZED_TELEMETRY=FALSE
    restart: unless-stopped
    networks:
      - otis-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/v1/heartbeat"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Ollama LLM Service
  ollama:
    image: ollama/ollama:latest
    container_name: otis-ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    restart: unless-stopped
    networks:
      - otis-network
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  # Telegram Bot (Optional)
  bot:
    build:
      context: .
      dockerfile: docker/Dockerfile.api
    container_name: otis-telegram-bot
    command: ["python", "-m", "src.bot.telegram_bot"]
    environment:
      - TELEGRAM_BOT_TOKEN=${TELEGRAM_BOT_TOKEN}
      - TELEGRAM_ADMIN_CHAT_ID=${TELEGRAM_ADMIN_CHAT_ID}
      - DATABASE_URL=postgresql://otis:otis_password@postgres:5432/otis
    depends_on:
      - postgres
      - api
    restart: unless-stopped
    networks:
      - otis-network
    profiles:
      - with-bot

  # Celery Worker Service (for distributed task execution)
  worker:
    build:
      context: .
      dockerfile: docker/Dockerfile.api
    container_name: otis-worker
    command: ["celery", "-A", "src.tasks", "worker", "--loglevel=info", "--concurrency=4"]
    environment:
      - DATABASE_URL=postgresql://otis:otis_password@postgres:5432/otis
      - OLLAMA_BASE_URL=http://ollama:11434
      - CHROMA_PERSIST_DIRECTORY=/app/data/chroma
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
    volumes:
      - ./data/chroma:/app/data/chroma
      - ./data/logs:/app/data/logs
    depends_on:
      - postgres
      - ollama
      - chroma
      - redis
    restart: unless-stopped
    networks:
      - otis-network
    deploy:
      replicas: 2  # Scale to 2 workers for high availability
    profiles:
      - with-worker

  # Tor proxy for Red Team anonymity
  tor-proxy:
    image: dperson/torproxy:latest
    container_name: otis-tor-proxy
    ports:
      - "9050:9050"  # SOCKS5 proxy
      - "9051:9051"  # Control port
    restart: unless-stopped
    networks:
      - otis-network

  # Red Team runner with professional tools
  red-team-runner:
    build:
      context: .
      dockerfile: docker/Dockerfile.red-team
    container_name: otis-red-team-runner
    environment:
      - DOCKER_HOST=tcp://socket-proxy:2375
    volumes:
      - /tmp/otis-artifacts:/artifacts
      - ./data/logs:/logs
    depends_on:
      - socket-proxy
      - tor-proxy
    restart: unless-stopped
    networks:
      - otis-network
    profiles:
      - red-team

  # Elasticsearch for log storage and analysis
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    container_name: otis-elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ports:
      - "9200:9200"
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    restart: unless-stopped
    networks:
      - otis-network
    profiles:
      - blue-team

  # Vector for log ingestion and processing
  vector:
    image: timberio/vector:latest-alpine
    container_name: otis-vector
    volumes:
      - ./config/vector.toml:/etc/vector/vector.toml:ro
      - ./data/logs:/logs
    depends_on:
      - elasticsearch
    restart: unless-stopped
    networks:
      - otis-network
    profiles:
      - blue-team

  # ElastAlert for real-time detection
  elastalert:
    image: jertel/elastalert2:latest
    container_name: otis-elastalert
    volumes:
      - ./config/elastalert:/opt/elastalert/rules
      - ./config/elastalert.yaml:/opt/elastalert/config.yaml:ro
    depends_on:
      - elasticsearch
    restart: unless-stopped
    networks:
      - otis-network
    profiles:
      - blue-team

  # C2 Framework (Havoc/Sliver)
  c2-server:
    image: havocframework/havoc:latest
    container_name: otis-c2-server
    ports:
      - "40056:40056"  # API
      - "443:443"      # HTTPS listener
    volumes:
      - c2_data:/data
    restart: unless-stopped
    networks:
      - otis-network
    profiles:
      - red-team

volumes:
  postgres_data:
  ollama_data:
  chroma_data:
  redis_data:
  elasticsearch_data:
  c2_data:

networks:
  # Zero-Trust Network Segmentation
  frontend-net:
    driver: bridge
    internal: false  # Exposed to internet
  
  db-net:
    driver: bridge
    internal: true  # Internal only
  
  ai-net:
    driver: bridge
    internal: true  # Internal only
  
  security-net:
    driver: bridge
    internal: true  # Isolated security operations
  
  obs-net:
    driver: bridge
    internal: true  # Observability/monitoring

